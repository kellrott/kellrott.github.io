[{"authors":null,"categories":null,"content":"","date":1566198000,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1566198000,"objectID":"67a14f3c299370ceabe68295176085be","permalink":"https://ellrottlab.org/authors/struck-a/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/struck-a/","section":"authors","summary":"","tags":null,"title":"Adam Struck","type":"authors"},{"authors":[""],"categories":null,"content":"After spending a career in consulting and startups it is a privilege to collaborate with great teams on such worthwhile, meaningful projects.\nCurrent research focus:  Increasing statistical power by lowering barriers to entry and streamlining access to diverse datasets Improving the reach of precision medicine by capturing evidence from integration, text mining and machine learning Facilitating reproducibility, reuse and cost via Graph databases and Cloud management  Areas of interest  Graph Databases Machine Learning Pan Cancer, Cross Project Data Harmonization  Memberships and associations  ga4gh cancervariants AnVIL  Publications   A harmonized meta-knowledgebase of clinical interpretations of cancer genomic variants - https://www.biorxiv.org/content/biorxiv/early/2018/07/11/366856.full.pdf\n  Exploring Integrative Analysis using the BioMedical Evidence Graph - https://www.biorxiv.org/content/biorxiv/early/2019/09/25/773911.full.pdf\n  Additional information  LinkedIn bwalsh.com  ","date":1548463464,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1548463464,"objectID":"7b953a5d2da2e118371f3a1496fdf89e","permalink":"https://ellrottlab.org/authors/walsh/","publishdate":"2019-01-25T16:44:24-08:00","relpermalink":"/authors/walsh/","section":"authors","summary":"After spending a career in consulting and startups it is a privilege to collaborate with great teams on such worthwhile, meaningful projects.\nCurrent research focus:  Increasing statistical power by lowering barriers to entry and streamlining access to diverse datasets Improving the reach of precision medicine by capturing evidence from integration, text mining and machine learning Facilitating reproducibility, reuse and cost via Graph databases and Cloud management  Areas of interest  Graph Databases Machine Learning Pan Cancer, Cross Project Data Harmonization  Memberships and associations  ga4gh cancervariants AnVIL  Publications   A harmonized meta-knowledgebase of clinical interpretations of cancer genomic variants - https://www.","tags":null,"title":"Brian Walsh","type":"authors"},{"authors":[""],"categories":[],"content":"","date":1534952582,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1534952582,"objectID":"d311f8616c3897a8051e88148b93494d","permalink":"https://ellrottlab.org/authors/smith/","publishdate":"2018-08-22T08:43:02-07:00","relpermalink":"/authors/smith/","section":"authors","summary":"","tags":null,"title":"Malisa Smith","type":"authors"},{"authors":[""],"categories":[],"content":"","date":1534952464,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1534952464,"objectID":"dbe30b1e475b94736a84a6217de434aa","permalink":"https://ellrottlab.org/authors/jeena-lee/","publishdate":"2018-08-22T08:41:04-07:00","relpermalink":"/authors/jeena-lee/","section":"authors","summary":"","tags":null,"title":"Jeena Lee","type":"authors"},{"authors":[""],"categories":[],"content":"","date":1534784903,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1534784903,"objectID":"50bc4e10cf6f7e3cbb96428a7670d032","permalink":"https://ellrottlab.org/authors/spangler/","publishdate":"2018-08-20T10:08:23-07:00","relpermalink":"/authors/spangler/","section":"authors","summary":"","tags":null,"title":"Ryan Spangler","type":"authors"},{"authors":[""],"categories":[],"content":"","date":1534784244,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1534784244,"objectID":"f3ea288add1e01b7cda6262a1558a377","permalink":"https://ellrottlab.org/authors/creason/","publishdate":"2018-08-20T09:57:24-07:00","relpermalink":"/authors/creason/","section":"authors","summary":"","tags":null,"title":"Allison Creason","type":"authors"},{"authors":[""],"categories":[],"content":"","date":1534784185,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1534784185,"objectID":"3f67c414400fad84a2bc4b98f1114580","permalink":"https://ellrottlab.org/authors/buchanan/","publishdate":"2018-08-20T09:56:25-07:00","relpermalink":"/authors/buchanan/","section":"authors","summary":"","tags":null,"title":"Alex Buchanan","type":"authors"},{"authors":null,"categories":null,"content":"My research is on cancer subtype predction for the NCI Tumor Molecular Pathalogy project.\n2014-2019 Student, Bioengineering, Washington State University\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"e1366a4654131f9a75f50992f9e2c49d","permalink":"https://ellrottlab.org/authors/karlberg/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/karlberg/","section":"authors","summary":"My research is on cancer subtype predction for the NCI Tumor Molecular Pathalogy project.\n2014-2019 Student, Bioengineering, Washington State University","tags":null,"title":"Brian Karlberg","type":"authors"},{"authors":null,"categories":null,"content":"My primary research goal is the application of large scale computing techniques and data integration for the analysis of genomics and systems biology. My current focus has been on biological systems analysis of cancer biology where I specialize in large scale computing problems that require heterogeneous analysis and data. For the past several years I have been extensively involved in the TCGA project, coordinating large scale variant calling efforts and enabling integrative analysis. I worked as the data coordinator for the TCGA PanCancer project, which was the joint effort of more than 100 scientists and my critical role allowed the publication of seventeen manuscripts.I have worked on several large compute platform projects, including working as the OHSU technical lead on the OHSU/Intel Collaborative Cancer Cloud and for the BioMedical Evidence Graph(BMEG). These projects have sought to enable researchers to utilize powerful computational systems to do large scale integrative analysis. I plan to use this experience to enable the next generation of integrative analysis. Despite an extensive history in computer engineering and the technological development of platforms for analysis, my work is guided by enabling actual analytical problems, with a principle goal of working with biological collaborators with to drive relevant research.\n 2000 Intern, University of California, Riverside 2001-02 Intern, Oak Ridge National Labs 2002-08 PhD. Student, University of Tennessee, Knoxville (Ying Xu, Advisor) 2003-08 Visiting student at University of Georgia, Athens 2009-11 Postdoctoral Associate, Burnham Institute (Adam Godzik, Advisor) 2012-15 Programmer Analyst, University of California, Santa Cruz (Josh Stuart, Advisor) 2013-14 Contractor, Sage Biosciences, Seattle2015-Assistant Professor, Oregon Health \u0026amp; Science University, Portland  ","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"24fc94ab375cad093935fd120b49d2e4","permalink":"https://ellrottlab.org/authors/kellrott/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/kellrott/","section":"authors","summary":"My primary research goal is the application of large scale computing techniques and data integration for the analysis of genomics and systems biology. My current focus has been on biological systems analysis of cancer biology where I specialize in large scale computing problems that require heterogeneous analysis and data. For the past several years I have been extensively involved in the TCGA project, coordinating large scale variant calling efforts and enabling integrative analysis.","tags":null,"title":"Kyle Ellrott","type":"authors"},{"authors":null,"categories":null,"content":"Jordan A. Lee is a computational biologist in Dr. Kyle Ellrott's lab at the OHSU Knight Cancer Institute. She is currently taking a multi-platform machine learning approach to predict tumor phenotypes through cross model performance and optimization analysis. Additionally, she is interrogating BMEG data integration builds and drug response consistency across established genomic sources and published literature to identify actionable gaps in cancer research. She is also investigating common single-cell protocols for confounding variables in order to suggest single-cell guidlines for researchers. Lastly, she is benchmarking RNA deconvolution algorithms of cancer patient samples and tumors generated through 3D bioprinting tumor cells.\n 2011-15 BS, University of Washington, Seattle, WA 2018-19 MS, University of Oregon, Eugene, OR  ","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"4c024dabc586ffb3e086d74147780d77","permalink":"https://ellrottlab.org/authors/lee-jordan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/lee-jordan/","section":"authors","summary":"Jordan A. Lee is a computational biologist in Dr. Kyle Ellrott's lab at the OHSU Knight Cancer Institute. She is currently taking a multi-platform machine learning approach to predict tumor phenotypes through cross model performance and optimization analysis. Additionally, she is interrogating BMEG data integration builds and drug response consistency across established genomic sources and published literature to identify actionable gaps in cancer research. She is also investigating common single-cell protocols for confounding variables in order to suggest single-cell guidlines for researchers.","tags":null,"title":"Jordan Lee","type":"authors"},{"authors":["Ellrott K","Buchanan A","Creason A","Mason M","Schaffter T","Hoff B","Eddy J","Chilton JM","Yu T","Stuart JM","Saez-Rodriguez J","Stolovitzky G","Boutros PC","Guinney J"],"categories":null,"content":"","date":1568098800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568098800,"objectID":"207f73215debb647c67382737ea4ce41","permalink":"https://ellrottlab.org/publication/31506093/","publishdate":"2019-09-10T00:00:00-07:00","relpermalink":"/publication/31506093/","section":"publication","summary":"Challenges are achieving broad acceptance for addressing many biomedical questions and enabling tool assessment. But ensuring that the methods evaluated are reproducible and reusable is complicated by the diversity of software architectures, input and output file formats, and computing environments. To mitigate these problems, some challenges have leveraged new virtualization and compute methods, requiring participants to submit cloud-ready software packages. We review recent data challenges with innovative approaches to model reproducibility and data sharing, and outline key lessons for improving quantitative biomedical data analysis through crowd-sourced benchmarking challenges.","tags":null,"title":"Reproducible biomedical benchmarking in the cloud: lessons from crowd-sourced data challenges","type":"publication"},{"authors":["Wood MA","Nguyen A","Adam Struck","Ellrott K","Nellore A","Thompson RF"],"categories":null,"content":"","date":1566198000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566198000,"objectID":"52999aaeb8a6189268895dc1013a20f6","permalink":"https://ellrottlab.org/publication/31424527/","publishdate":"2019-08-19T00:00:00-07:00","relpermalink":"/publication/31424527/","section":"publication","summary":"MOTIVATION: The vast majority of tools for neoepitope prediction from DNA sequencing of complementary tumor and normal patient samples do not consider germline context or the potential for co-occurrence of two or more somatic variants on the same mRNA transcript. Without consideration of these phenomena, existing approaches are likely to produce both false positive and false negative results, resulting in an inaccurate and incomplete picture of the cancer neoepitope landscape. We developed neoepiscope chiefly to address this issue for single nucleotide variants (SNVs) and insertions/deletions (indels). RESULTS: Herein, we illustrate how germline and somatic variant phasing affects neoepitope prediction across multiple datasets. We estimate that up to ∼5% of neoepitopes arising from SNVs and indels may require variant phasing for their accurate assessment. neoepiscope is performant, flexible, and supports several major histocompatibility complex binding affinity prediction tools.","tags":null,"title":"Neoepiscope improves neoepitope prediction with multi-variant phasing","type":"publication"},{"authors":null,"categories":null,"content":"The NCI's Genomic Data Analysis Network (GDAN) was launched in 2016 to continue the work started by the TCGA in the analysis of large cancer cohorts.\n","date":1548614065,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548614065,"objectID":"8cdb676104bbf6a5fc5883bab47c6baa","permalink":"https://ellrottlab.org/project/gdan/","publishdate":"2019-01-27T10:34:25-08:00","relpermalink":"/project/gdan/","section":"project","summary":"The NCI's Genomic Data Analysis Network (GDAN) was launched in 2016 to continue the work started by the TCGA in the analysis of large cancer cohorts.","tags":["Cancer Biology"],"title":"GDAN","type":"project"},{"authors":null,"categories":null,"content":"The NHGRI Genomic Data Science Analysis, Visualization, and Informatics Lab-Space (AnVIL) is a project to build a data commons to allow researchers to efficiently analyze and visualize genomics data on the cloud. This project is a collaboration with Oregon Health and Science University, University of California Santa Cruz, University of Chicago, The Broad Institute, Washington University in St. Louis, Vanderbilt University Medical Center, Johns Hopkins University and Pennsylvania State University.\n","date":1548613640,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548613640,"objectID":"56790934b27066223bdb381af82ddda9","permalink":"https://ellrottlab.org/project/anvil/","publishdate":"2019-01-27T10:27:20-08:00","relpermalink":"/project/anvil/","section":"project","summary":"The NHGRI Genomic Data Science Analysis, Visualization, and Informatics Lab-Space (AnVIL) is a project to build a data commons to allow researchers to efficiently analyze and visualize genomics data on the cloud. This project is a collaboration with Oregon Health and Science University, University of California Santa Cruz, University of Chicago, The Broad Institute, Washington University in St. Louis, Vanderbilt University Medical Center, Johns Hopkins University and Pennsylvania State University.","tags":["Data Systems"],"title":"AnVIL","type":"project"},{"authors":[],"categories":[],"content":"The NHGRI Genomic Data Science Analysis, Visualization, and Informatics Lab-space (AnVIL) project will provide a platform for researchers to study Genomic data in the cloud. As part of this project, we will be providing methods to enable analysis APIs.\n","date":1543187570,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543187570,"objectID":"8fdcd6eceecc7879c9c2cbaa7e6f7042","permalink":"https://ellrottlab.org/post/anvil/","publishdate":"2018-11-25T15:12:50-08:00","relpermalink":"/post/anvil/","section":"post","summary":"The NHGRI Genomic Data Science Analysis, Visualization, and Informatics Lab-space (AnVIL) project will provide a platform for researchers to study Genomic data in the cloud. As part of this project, we will be providing methods to enable analysis APIs.","tags":[],"title":"Starting work on the AnVIL","type":"post"},{"authors":["Lee AY","Ewing AD","Ellrott K","Hu Y","Houlahan KE","Bare JC","Espiritu SMG","Huang V","Dang K","Chong Z","Caloian C","Yamaguchi TN","ICGC-TCGA DREAM Somatic Mutation Calling Challenge Participants","Kellen MR","Chen K","Norman TC","Friend SH","Guinney J","Stolovitzky G","Haussler D","Margolin AA","Stuart JM","Boutros PC"],"categories":null,"content":"","date":1541491200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541491200,"objectID":"0ec5c6471c209f5ab770e06cc2e5f830","permalink":"https://ellrottlab.org/publication/30400818/","publishdate":"2018-11-06T00:00:00-08:00","relpermalink":"/publication/30400818/","section":"publication","summary":"BACKGROUND: The phenotypes of cancer cells are driven in part by somatic structural variants. Structural variants can initiate tumors, enhance their aggressiveness, and provide unique therapeutic opportunities. Whole-genome sequencing of tumors can allow exhaustive identification of the specific structural variants present in an individual cancer, facilitating both clinical diagnostics and the discovery of novel mutagenic mechanisms. A plethora of somatic structural variant detection algorithms have been created to enable these discoveries; however, there are no systematic benchmarks of them. Rigorous performance evaluation of somatic structural variant detection methods has been challenged by the lack of gold standards, extensive resource requirements, and difficulties arising from the need to share personal genomic information. RESULTS: To facilitate structural variant detection algorithm evaluations, we create a robust simulation framework for somatic structural variants by extending the BAMSurgeon algorithm. We then organize and enable a crowdsourced benchmarking within the ICGC-TCGA DREAM Somatic Mutation Calling Challenge (SMC-DNA). We report here the results of structural variant benchmarking on three different tumors, comprising 204 submissions from 15 teams. In addition to ranking methods, we identify characteristic error profiles of individual algorithms and general trends across them. Surprisingly, we find that ensembles of analysis pipelines do not always outperform the best individual method, indicating a need for new ways to aggregate somatic structural variant detection approaches. CONCLUSIONS: The synthetic tumors and somatic structural variant detection leaderboards remain available as a community benchmarking resource, and BAMSurgeon is available at https://github.com/adamewing/bamsurgeon .","tags":null,"title":"Combining accurate tumor genome simulation with crowdsourcing to benchmark somatic structural variant detection.","type":"publication"},{"authors":["Alex Buchanan"],"categories":[],"content":"Handling Failures from OpenStack Swift in Funnel When building distributed services, handling failures from other services is a fact of life.\nWe use OpenStack Swift as our object storage service, and we use Funnel to transfer thousands of objects to and from Swift. Failed transfers have been common; the Swift server ca be unavailable, overloaded, and even lose chunks of data during upload.\nIt’s been challenging to make Funnel tolerant to all these failures, improved our logs and tools available for debugging, improved our code, and we’ve learned a lot along the way.\nRetries At the core of handling failures is being able to retry failed requests.\nIn Funnel, we retry most failed requests to external services. We do this by wrapping our APIs in a generic utility which can replay the same request until it succeeds. For example,\n// Storage is the interface we want to wrap. type Storage interface { Put(sourcePath, destURL string) error } // NewStorageRetrier creates a wrapper around Storage which includes retry logic. func NewStorageRetrier(backend Storage) *StorageRetrier { return StorageRetrier{ Backend: backend, Retrier: util.Retrier{ // At first, retry after one second. InitialInterval: time.Second, // Each successive retry will wait twice as long before retrying. Multiplier: 2.0, // Retry for up to an hour. MaxElapsedTime: 60*time.Minute, // ShouldRetry decides whether the error can be retried. ShouldRetry: func(err error) bool { switch err { // Retry if the uploaded object isn't the same, // the service is unavailable, etc. case swift.ObjectCorrupted, swift.TimeoutError, swift.UnavailableError: return true default: return false } }, }, } }  The code here is simplified for this post, the real code is here.\nOur storage code will now attempt to upload the file multiple times until it succeeds. Funnel will try hard to upload, retrying for up to an hour.\nTesting The hard part about debugging failures is that they are often intermittent and difficult to reproduce.\nSetting up a system which can deterministically reproduce specific types of failures takes some work, but it can be very useful and may be worth the price of admission.\nLuckily, there are tools out there to help.\ntoxy toxy is a proxy server which can be configured to inject errors into network traffic.\nvar toxy = require('toxy') var poisons = toxy.poisons var rules = toxy.rules var proxy = toxy() // Forward traffic to the actual Swift server proxy.forward('http://swift.actual:8080') // Inject \u0026quot;Object corrupted\u0026quot; errors into uploads, // which happens when the uploaded object doesn't match // the file being uploaded (meaning something got lost). proxy .put('/*/buchanan/funnel-test/object-corrupted') .poison(poisons.inject({ code: 200, // Change the object's etag (checksum) in the response to the PUT. // // This is how swift communicates to the client the checksum of the // object that was uploaded, so we force it to be corrupt here. headers: {'ETag': 'zzzzzzzzzf1a4e663f02245d42832766'} })) // Only corrupt the object 60% of the time. .withRule(rules.probability(60)) // Simulate the service being unavailable. proxy .all('/*/buchanan/funnel-test/service-unavailable') .poison(poisons.inject({ code: 503, body: '{\u0026quot;error\u0026quot;: \u0026quot;toxy injected error\u0026quot;}', headers: {'Content-Type': 'application/json'} })) .withRule(rules.probability(60)) proxy.all(\u0026quot;/*\u0026quot;) proxy.listen(8000)  The code above will proxy Swift traffic, injecting errors into traffic 60% of the time.\nThe failures can be accessed by pointing Funnel’s Swift client to this proxy, and uploading to a specific object URL:\nexport FUNNEL_SWIFT_STORAGE_URL=http://fake.swift:8000/v1/AUTH_abcedfg funnel storage put swift://buchanan/funnel-test/service-unavailable  Now we can tweak the proxy errors and fix Funnel code at the same time, easily working out the kinks in error handling, and having confidence that Funnel is retrying requests correctly.\nRetry screenshot\ntcpdump tcpdump allows you to monitor network traffic and inspect low-level packets. Incredibly useful for figuring out what’s going on with Swift and getting the proxy set up.\nsudo tcpdump -n not port 22 and not icmp and not arp  This article does a great job at explaining the power of tcpdump.\niptables At first, I wasn’t easily able to forward Funnel’s traffic to the Swift proxy via configuration alone, so I dug into Linux’s network layer using iptables to forward traffic to the proxy server.\niptables is an intimdating and complex tool, but also extremely powerful and capable of routing traffic almost anyway you can imagine.\nThe rule below watch for traffic going out to the actual Swift server (at 1.2.3.4:8080) and rewrites the IP address to point to the proxy instead (at 9.8.7.6:8080).\nsudo iptables -t nat -A OUTPUT -p tcp -d 1.2.3.4 --dport 8080 -j DNAT --to-destination 9.8.7.6  This article does a decent job of introducing iptables.\n","date":1535224162,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535224162,"objectID":"7214897d2c4cbc9865d9345fa018f3df","permalink":"https://ellrottlab.org/post/network-failures/","publishdate":"2018-08-25T11:09:22-08:00","relpermalink":"/post/network-failures/","section":"post","summary":"Handling Failures from OpenStack Swift in Funnel When building distributed services, handling failures from other services is a fact of life.\nWe use OpenStack Swift as our object storage service, and we use Funnel to transfer thousands of objects to and from Swift. Failed transfers have been common; the Swift server ca be unavailable, overloaded, and even lose chunks of data during upload.\nIt’s been challenging to make Funnel tolerant to all these failures, improved our logs and tools available for debugging, improved our code, and we’ve learned a lot along the way.","tags":["Development"],"title":"Debugging Network Failures","type":"post"},{"authors":null,"categories":null,"content":"","date":1534953736,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534953736,"objectID":"eef66b4357cdc068e3525d0f8b3228ed","permalink":"https://ellrottlab.org/project/g2p/","publishdate":"2018-08-22T09:02:16-07:00","relpermalink":"/project/g2p/","section":"project","summary":"","tags":["API"],"title":"GA4GH G2P","type":"project"},{"authors":null,"categories":null,"content":"","date":1534952235,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534952235,"objectID":"2b93de970c7255d992b26c8f0e60d601","permalink":"https://ellrottlab.org/project/smc-het/","publishdate":"2018-08-22T08:37:15-07:00","relpermalink":"/project/smc-het/","section":"project","summary":"","tags":["Dream Challenge"],"title":"SMC  Het","type":"project"},{"authors":null,"categories":null,"content":"","date":1534745971,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534745971,"objectID":"d5461bcaf08d44841bc62f193a0442e2","permalink":"https://ellrottlab.org/project/grip/","publishdate":"2018-08-19T23:19:31-07:00","relpermalink":"/project/grip/","section":"project","summary":"GRaph Integration Platform","tags":["Data Systems"],"title":"Grip","type":"project"},{"authors":["Ellrott K","Bailey MH","Saksena G","Covington KR","Kandoth C","Stewart C","Hess J","Ma S","Chiotti KE","McLellan M","Sofia HJ","Hutter C","Getz G","Wheeler D","Ding L","MC3 Working Group; Cancer Genome Atlas Research Network."],"categories":null,"content":"","date":1522566000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1522566000,"objectID":"501c051962db321a78845a94064db215","permalink":"https://ellrottlab.org/publication/29596782/","publishdate":"2018-04-01T00:00:00-07:00","relpermalink":"/publication/29596782/","section":"publication","summary":"The Cancer Genome Atlas (TCGA) cancer genomics dataset includes over 10,000 tumor-normal exome pairs across 33 different cancer types, in total 400 TB of raw data files requiring analysis. Here we describe the Multi-Center Mutation Calling in Multiple Cancers project, our effort to generate a comprehensive encyclopedia of somatic mutation calls for the TCGA data to enable robust cross-tumor-type analyses. Our approach accounts for variance and batch effects introduced by the rapid advancement of DNA extraction, hybridization-capture, sequencing, and analysis methods over time. We present best practices for applying an ensemble of seven mutation-calling algorithms with scoring and artifact filtering. The dataset created by this analysis includes 3.5 million somatic variants and forms the basis for PanCan Atlas papers. The results have been made available to the research community along with the methods used to generate them. This project is the result of collaboration from a number of institutes and demonstrates how team science drives extremely large genomics projects..","tags":null,"title":"Scalable Open Science Approach for Mutation Calling of Tumor Exomes Using Multiple Genomic Pipelines","type":"publication"},{"authors":["Mehmet Gönen","Barbara A Weir","Glenn S Cowley","Francisca Vazquez","Yuanfang Guan","Alok Jaiswal","Masayuki Karasuyama","Vladislav Uzunangelov","Tao Wang","Aviad Tsherniak","Sara Howell","Daniel Marbach","Bruce Hoff","Thea C Norman","Antti Airola","Adrian Bivol","Kerstin Bunte","Daniel Carlin","Sahil Chopra","Alden Deran","Kyle Ellrott","Peddinti Gopalacharyulu","Kiley Graim","Samuel Kaski","Suleiman A Khan","Yulia Newton","Sam Ng","Tapio Pahikkala","Evan Paull","Artem Sokolov","Hao Tang","Jing Tang","Krister Wennerberg","Yang Xie","Xiaowei Zhan","Fan Zhu","Broad-DREAM Community","Tero Aittokallio","Hiroshi Mamitsuka","Joshua M Stuart","Jesse S Boehm","David E Root","Guanghua Xiao","Gustavo Stolovitzky","William C Hahn","Adam A Margolin"],"categories":null,"content":"","date":1509519600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1509519600,"objectID":"23f17196b4578e7e28a67df7b49c6671","permalink":"https://ellrottlab.org/publication/28988802/","publishdate":"2017-11-01T00:00:00-07:00","relpermalink":"/publication/28988802/","section":"publication","summary":"We report the results of a DREAM challenge designed to predict relative genetic essentialities based on a novel dataset testing 98,000 shRNAs against 149 molecularly characterized cancer cell lines. We analyzed the results of over 3,000 submissions over a period of 4 months. We found that algorithms combining essentiality data across multiple genes demonstrated increased accuracy; gene expression was the most informative molecular data type; the identity of the gene being predicted was far more important than the modeling strategy; well-predicted genes and selected molecular features showed enrichment in functional categories; and frequently selected expression features correlated with survival in primary tumors. This study establishes benchmarks for gene essentiality prediction, presents a community resource for future comparison with this benchmark, and provides insights into factors influencing the ability to predict gene essentiality from functional genetic screens. This study also demonstrates the value of releasing pre-publication data publicly to engage the community in an open research collaboration.","tags":null,"title":"A Community Challenge for Inferring Genetic Predictors of Gene Essentialities through Analysis of a Functional Screen of Cancer Cell Lines.","type":"publication"},{"authors":["Yulia Newton","Adam M Novak","Teresa Swatloski","Duncan C McColl","Sahil Chopra","Kiley Graim","Alana S Weinstein","Robert Baertsch","Sofie R Salama","Kyle Ellrott","Manu Chopra","Theodore C Goldstein","David Haussler","Olena Morozova","Joshua M Stuart"],"categories":null,"content":"","date":1509519600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1509519600,"objectID":"0b25f666639723eed73a3c74ab735f30","permalink":"https://ellrottlab.org/publication/29092953/","publishdate":"2017-11-01T00:00:00-07:00","relpermalink":"/publication/29092953/","section":"publication","summary":"Vast amounts of molecular data are being collected on tumor samples, which provide unique opportunities for discovering trends within and between cancer subtypes. Such cross-cancer analyses require computational methods that enable intuitive and interactive browsing of thousands of samples based on their molecular similarity. We created a portal called TumorMap to assist in exploration and statistical interrogation of high-dimensional complex 'omics' data in an interactive and easily interpretable way. In the TumorMap, samples are arranged on a hexagonal grid based on their similarity to one another in the original genomic space and are rendered with Google's Map technology. While the important feature of this public portal is the ability for the users to build maps from their own data, we pre-built genomic maps from several previously published projects. We demonstrate the utility of this portal by presenting results obtained from The Cancer Genome Atlas project data.","tags":null,"title":"TumorMap: Exploring the Molecular Similarities of Cancer Samples in an Interactive Portal.","type":"publication"},{"authors":["Adam Margolin","Josh Stuart","Kyle Ellrott"],"categories":[],"content":"In 2014, Dr. Margolin, Dr. Stuart and Dr. Ellrott wrote a draft white paper outlining the need for a computational model to efficiently communicate known Genotype/Phenotype association. This working group would eventually evolve into Variant Interpretation for Cancer Consortium VICC.\nMany of the ideas and goals changed of the project changed over the years. Below is the original whitepaper draft, to show how much the project has evolved.\nGA4GH Genotypes to Phenotypes (G2P) Task Team Motivation One of the most important goals driving the collection of genome sequence information is to understand how particular variants lead to observable phenotypes and treatment options. Yet no standards exist on how to describe genotype to phenotype (G2P) relationships. Several databases exist that have begun to collect G2P information such as PharmGKB, my cancer genome, MD Anderson’s personalized therapy knowledge base, ClinVar, SNPeff, OMIM, and the Human Gene Mutation Database. However, it is not possible to compare or aggregate data from these disparate sources because each use their own terminologies. Additionally, prediction of G2P relationships is an extremely active research area, with thousands of papers proposing novel signatures, biomarkers, and mathematical models to predict a given phenotype, and multiple crowd-sourced challenges soliciting thousands of models from the community around G2P problems such as prediction of breast cancer prognosis, response to rheumatoid arthritis therapy, and sensitivity of cancer cell lines to small molecular or shRNA treatments. Because no standards exist for representing such computationally derived predictions, it is difficult to compare the accuracy of different predictors for a given problem, leading to inconsistency and lack of clarity regarding bona-fide predictive signatures, and models trained on a given dataset are not easily applied to G2P prediction in related datasets, making it difficult to assess robustness or gain knowledge of signatures related to multiple phenotypes.\nOther GA4GH working groups are creating standards for representing and computing on genetic and clinical (phenotype) data. We aim to build on and connect the work of these GA4GH groups, by defining standard data representations and building out a computable resource of G2P relationships. Formally, G2P relations may be described as a triple (see Goals for the API Specification) with Genotype(G), Phenotype(P) and Connection(C). Other GA4GH groups are defining standards for G and P, while our group will define standards for C.\nA successful, long-term implementation would be able to represent G2P relationships derived from multiple sources, including those approved for clinical actionability, derived from the literature, or inferred from data analysis. This implementation would also represent both simple G2P relationships associated with a single genetic variant, as well as more complex G2P relationships in which phenotype is defined as a multi-variate function incorporating multiple omics data types and prior knowledge, such as pathway relationships.\nDriving Pilot Projects We propose pilot projects that initially implement the simpler use case (literature-derived, single variant relationships) while building up towards the more complex use case of computationally-derived multi-variate relationships.\nProject 1. Extract genotype-to-phenotype information from the literature. Our first driving project will build both the representation standards and initial implementation of a publicly available clinical genomics database derived from literature-based associations between a genetic variant and a phenotype. We will initially focus on cancer genetic variants linked to therapeutic response. We will then expand to represent genetic variants corresponding to risk or diagnostic markers of non-cancer genetic diseases.\nMany efforts at cancer centers across the world are now focusing on developing a clinical genomics database to guide precision medicine treatment decisions. Therefore, we believe a GA4GH initiative could be of great benefit to the community, by defining standards to create compatibility across these multiple efforts, and creating an open community resource that will eliminate redundancy across efforts.\nOur group will include leaders of prominent clinical genomics efforts, including: Gordon Mills, who leads MDAnderson’s personalized cancer therapy initiative (https://pct.mdanderson.org/); Chris Corless, who leads the Knight Diagnostic Lab at OHSU, and Rodrigo Dienstmann, who created the clinical genomics database for Massachussets General Hostpital. Taken together, these efforts have compiled hundreds of G2P associations, and proposed structured data representations. Once our project is formalized, we will reach out to other people leading prominent international clinical genomics efforts. Through discussions among these experts, we will create a representational standard that allows information across these databases to be merged. Clinical experts will work closely with professional engineers, from Google and elsewhere, to codify and implement agreed upon ideas into a computable resource.\nProject 2. Compare literature derived biomarker / drug clinical associations with (simple) computationally inferred biomarker / drug response associations. This project is designed to explore a simple example of connecting literature-derived associations from the clinical genomics database (project 1) to data-derived predictions from analysis of pharmacogenomic screens. We will utilize data from large-scale pharmacogenomic projects, including the Cancer Cell Line Encyclopedia (CCLE), Sanger Genomics of Drug Sensitivity (Sanger), and Broad’s Cancer Target Discovery and Development (CTDD) network screens. Each dataset contains several hundred cell lines with molecular characterization (gene expression, copy number, mutation) and sensitivity to a panel of compounds. Here we will begin by representing associations between mutations and sensitivity, calculated by simple univariate statistics, such as correlation.\nWe will standardize: 1) the representation of sample metadata (in collaboration with the GA4GH metadata group) across the clinical genomic database and the cell line samples; and 2) the representation of associations inferred from the literature (clinical genomics database) and computationally.\nThe driving scientific question will be to evaluate the consistency of literature-reported associations in cell line pharmacogenomic models, and to evaluate the tumor-type specificity of associations between genotype and drug response. That is, for all variant-drug response associations used in clinical decision making for a given tumor type, we will assess the correlation between the same variant and drug response across all other tumor types profiled in the cell line panel.\nFor each drug, X, used in cell line studies. For each variant, V, reported in the clinical genomics database to be associated with response to drug X in tumor type Y. Compute Corr_Y as the correlation in cell line studies between response to drug X and presence of variant V in tumor type Y. Compute Corr_other as the correlation in cell line studies between response to drug X and presence of variant V in all tumor types other than Y. (optionally) Compute Corr_subset as the correlation in cell line studies between response to drug X and presence of variant V in tumor types related to Y (e.g. other haematopoeitic cancers).\nThis study will yield the following scientific outputs: By assessing the distribution of Corr_Y, we will determine the extent to which pharmacogenomic screens represent current clinically actionable G2P relationships. By assessing the distribution of Corr_Y in subsets of tumor types, we will determine if pharmacogenomic screens are better models of G2P for certain classes of compounds (e.g. we might expect cell intrinsic signalling inhibitors to show signal in cell lines, but not those dependent on microenvironment interactions). By comparing the distribution of Corr_Y to Corr_other we will determine the extent to which clinically actionable G2P relationships are tumor type dependent versus dependent on cell-type-independent genetic alterations. By comparing the distribution of Corr_Y to Corr_subset we will recommend potential opportunities to expand the indication for a given drug to other tumor types.\nIn addition to meeting the technical goal of harmonizing G2P derived from literature and computation, we believe this will represent the most comprehensive study to date assessing the extent to which clinically actionable G2P associations are dependent on tumor type vs. pan-tumor genetic alterations. We believe this will provide valuable information on the feasibility of running genomically guided, cross-tissue-type clinical trials.\nProject 3 \u0026ndash; Using data from the Beat-AML functional genomics program, develop an initial specification allowing: models to be trained on a given dataset; stored in a central system; queried for predictions in a new dataset; and re-trained on a different dataset. In project 3 we will tackle the problem of representing complex computationally inferred predictive models consisting of many variables and input data types. We will build this implementation using data from OHSU’s Beat-AML program \u0026ndash; which will ultimately collect data on 1,000 primary AML patient samples, including RNA-seq and whole exome sequencing, and ex vivo viability screens after treatment with 200 siRNAs and 100 small molecules. Data currently exists on ~100 patients and will grow at the rate of 200 additional patients per year, reaching 1,000 patients within 5 years.\nThe ongoing accrual of patient samples throughout the duration of the project provides an opportunity to perform prospective assessment of model predictions and iteratively refine models as new data is accrued. Moreover, the genomic profiling information generated for patients enrolled in this study will be used to provide them with cutting-edge genomically guided treatment options. Therefore, this study provides an ideal use case for integrating information from the clinical genomics database (project 1) with computationally derived predictions on the same patients. We envision that our model specification will borrow from or extend existing language independent machine learning APIs, such as the Google prediction API. We will assess and leverage such existing tools to create a standard model specification, including capabilities such as methods for train and predict, and structured representations of performance statistics such as cross validation accuracy. We envision that other aspects of the specification will be specific to G2P applications, including specifications for representing biomarkers or predictive signatures inferred by the model. Such a specification should be context-aware of the input data types, and thus able to represent biomarkers inferred at the gene level, data type level (e.g. mutation vs. copy number), or possibly pathway level. G2P associations inferred by such predictive models should be compatible with G2P association stored in the clinical genomics database, allowing comparison of computationally inferred predictors with those used in clinical care or reported in the literature. Every 3 months roughly 50 new samples will be profiled by Beat-AML. We envision training a number of different models on all samples generated up to that point (excluding the 50 new samples) and storing a representation of each trained model, including cross validation performance statistics. Each model will then be used to predict sensitivity to each compound and siRNA in the 50 new samples, and the correlation between predicted vs. measured sensitivities will be computed in the new samples (i.e. the test accuracy). We will compare the cross validation accuracy to the test accuracy across all models. For models that achieve high test accuracy, we will query for inferred functional biomarkers, which will be: compared to associations in the clinical genomics database; functionally experimentally validated; and ultimately used to augment clinical reports to suggest additional treatment options for patients who have exhausted standard of care. Additionally, all models will be retrained, including the additional 50 samples, and assessed again based on the next batch of 50 samples, thus providing robustness statistics of model accuracy in multiple rounds of prospective assessment.\nProject 4. Develop a library of predictors to connect tumor samples to phenotypic outcomes We will develop a library of predictors that can be queried against to annotate new samples, such as those from the Beat-AML project described above. We will focus on the use of gene expression data, primarily RNA-Seq, as omics features to train machine-learning predictors. Identifying accurate predictors allows gene expression signatures to be used as surrogates for phenotypic (or even genotypic) events. Because a rich set of phenotypic information is more readily available from model systems such as cell lines and xenografts, it remains a challenge to connect the results found in these models to actual patient tumors. This project closes the gap by connecting tumor samples to outcomes using gene expression as the common comparator (in the same spirit as the Connective Map project). TCGA tumor samples will be connected to drug response and gene essentiality found in cell lines using the predictor library.\nTo this end, we will develop recognizers based on cell line models. For this, we will develop drug sensitivity predictors using all of the CCLE data. In addition, we will use the Achilles dataset to develop predictors of gene essentiality across a diverse set of cell lines. We will then perform an all-against-all comparison of predictors trained on cell lines to those trained on TCGA samples. For each prediction task, we will test a library of machine-learning classifiers for their accuracy on the defined outcome challenges. We will start with simple linear classifiers (or penalized versions) to populate the initial library. Only recognizers performing significantly better than chance, based on cross-validation performance, will be added to the library. Once added to the library, a background distribution will be constructed for every accurate recognizer using positive and negative samples not included in training. This will enable the detection of a case when a new sample is significantly “recognized” by an entry in the library as a sample with an extreme score on the background distribution. We will assess the biological significance of these inferences by checking the degree to which a set of positive control samples (e.g. HER2 breast cancer samples) are connected to the appropriate recognizers (HER2 inhibitor sensitivity recognizer).\nIn addition, we will populate the library with predictors trained from the TCGA datasets. Co-lead Stuart has led the TCGA Pan-Cancer project. A benchmark will be created with the current “Pan-Cancer-12” dataset, data from Sage Bionetwork’s TCGA Live collection, and later replaced with results from the Pan-Cancer-21. We will include predictors developed to predict mutation status for the most frequently mutated genes, expression-based subtypes within tumor types, expression-based subtypes across tumor types, and clinical outcomes within each tumor type. In a similar way as described for the cell line predictors, background distributions can be generated for accurate classifiers. We can then apply the recognizers back on to the cell line samples. This will give an important “reciprocal” view on the connections between the tumor sample and cell line data sets. We may find, that patients with a particular mutation (e.g. BRAF) are predicted to be sensitive to a similar drug (e.g. vemurafinib) by comparing the output of a tumor sample predictor (BRAF vs non-BRAF mutant) against a cell line predictor (vemerafinib sensitive vs resistant).\nOnce we establish the library and demonstrate its biological significance, we will develop an API allow querying from any tumor- or cell line-based predictor. We will test the utility by applying the library to the re-analysis of the Beat-AML samples described above.\nSharing Information Without Compromising Patient Privacy A successful description would enable remote repositories to exchange G2P information without compromising patient privacy. Medical centers and hospitals are beginning to amass a large amount of genomics and functional genomics data along with other clinical and demographic information in patient records. Due to patient privacy concerns, protected health information (PHI) is kept behind firewalls to maintain compliance with state and federal laws. For routine care, this protection of data suffices. However, there are cases where it is vital to connect observations across institutions (e.g. to spot trends among patients with rare disorders). It could mean the difference between health and suffering for an institute to be able to share with another doctor (or parent) that a particular variant is predicted to be causal for a particular rare disease, is associated with several possible symptoms, and that several treatment strategies have been tried with varying degrees of success. See for example the story by Matt Might about his son Bertrand’s rare genetic disorder and how they only were able to track down other children with the disease because his blog went viral, due mainly to his blog’s prior popularity. In most cases it is nearly impossible for parents and doctors to make such connections.\nGoals for the API specification. The API will describe the types of G2P relations over which possible queries can be expressed. Relations will be described as a triple with Genotype(G), Phenotype(P) and Connection(C). Since other working groups in the GA4GH are fleshing out G and P, this group is focused on the ontology specification for the method of connections C. The element G represents a data structure which would describe combinations of genomic location, genomic event type, gene symbol link, and a link to a sample. Furthermore, it would encompass other “omics” data to describe cellular and tissue states beyond the genotype such as copy number (e.g. from SNP6 chips), the transcriptome (e.g. RNA-seq vector of gene levels), epigenome (e.g. DNA methylation estimates), proteome (e.g. reverse-phase protein arrays), metabolome, and so on, If any of those elements is omitted, it is treated as a wildcard, ie if a gene like TP53 is defined, with a genomic event as MUTATION, but no sample defined, it matches all samples with TP53 mutations.\nThe API would allow the user to query using a chain of triple statements, where a subset of each triples items is a some sort of selection operation, such as a wildcards or comparison operators. In the following examples, each triple is in the order (G, P, C):\nTo motivate the discussion, consider the following several use cases:\nUse Case 1 - Given a specific phenotype of interest (e.g. cardiomyopathy, cancer subtype, drug sensitivity, etc) list all genes with a non-synonymous mutation in a sample w/ the phenotype. UC1 is a query of the type (*,*,P) which gives all genotypes associated with a phenotype no matter what the method was that determined the connection.\nUse Case 2 - (inverse to UC1) - Given a specific variant in a particular gene, list all phenotypes observed with specific evidence code (e.g. inferred author statement, direct assay, predicted by gene expression classifier, etc). UC2 is a query of the type (G,,) which gives all phenotypes associated with a phenotype no matter what the method was that determined the connection.\nUse Case 3 - Given a (genotype, phenotype) pair such as (V600E in BRAF, responsive to vemurafinib) return if and what kind of evidence supports the association (e.g. clinical trial ). UC3 is a query of the type (G, C_clinicaltrial, P), that uses a defined comparison function to find clinical trials edges.\nUse Case 4 - Given a gene of interest A, are there events in any other genes B that are mutually exclusive with events in A across a specified cohort (or several cohorts). UC4 would be coded as MutuallyExclusive( [ (G_geneA, C_belongs, P_cohort), (*, C_belongs, P_cohort) ] ), where G_geneA selects genomic events related to gene A, C_belongs is the predicate defines that a genotypes sample belongs to a particular cohort, P_cohort, and the second selection connect all variants also connected to that cohort. The function \u0026lsquo;MutuallyExclusive\u0026rsquo; takes the selection and finds genes that are mutually exclusive in occurrence across samples. These kinds of server side functions allow the users to do statistical analysis across cohorts without having to transfer all of the data across the network.\nUse Case 5 - Similar to UC4 - Are there other genes B that have events that are coincident with events of a particular kind in gene A? UC5 would be coded as Correlated( [ (G_geneA, C_belongs, P_cohort), (*, C_belongs, P_cohort) ], 0.9 ) which would list all Genes in the sample cohort with a correlation above 0.9.\nUse Case 6 - Given a sample’s specific combination of variants and/or omics profiles, return the most associated phenotypes (predicted or assayed). UC6 would be coded as MaxLink_P( [ G_gene1, *, * ], [ G_gene2, *, *], …, [G_geneN, *, *] ), where the would be an N element description profiling the genomic elements of query, and MapLink_P would find the top hits that match these genomic features.\nAppendix A \u0026ndash; Engineering notes We feel that the best way to represent large scale relational data would be through the use a of Graph Database. SQL based systems are inflexible and hard to evolve, while also being very difficult to scale onto distributed systems. The alternative to SQL, key-value or document based NoSQL systems, are flexible and scale well, but most NoSQL based datastores only have soft relational data constructs. Graph Databases have many of the NoSQL benefits, the flexibility to deal with changing requirements, the ability to distribute data and scale horizontally while maintaining relationships as a core construct in the data store.\nSuch a system would be easy to design against, and would be ready for continually evolving data relationships. Most ontological descriptions of phenotypes would be available in RDF (http://www.bioontology.org/), and many biological projects already distribute data in this graph based format (ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/rdf/ http://bio2rdf.org/).\nRDF is a triple based graph description. This means that the entire graph is described in statements or \u0026lsquo;source node A connects via edge type B to node C\u0026rsquo;. This means that the resulting graph is only composed of nodes and edges. This graph model is much simpler then a full property graph, where each node and edge is allowed to have a set of key/value pairs attached to it. For dense genomic data a property graph would be a more concise way of describing complex relationships that involve many properties, coefficients and edge weights. We also believe that it is important to not only define the data transfer standards but the APIs to make remote interrogation of the data available.\nThere exists APIs for graph queries, such as SPARQL, which have been designed directly for RDF. However this system does not directly apply to the property based graphs we have proposed using. Our work with Graph Databases indicate that Gremlin may be more in line with the idea of a property graph based system. In addition, gremlin has already been shown to be easily convertable to a Map-Reduce based architecture (http://thinkaurelius.github.io/faunus/ https://github.com/kellrott/sparkgraph), so it will be easier to scale to extremely large datasets.\n","date":1483297561,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483297561,"objectID":"fe0be6815de745a0af1d4d5d2b2de7aa","permalink":"https://ellrottlab.org/post/g2p-whitepaper/","publishdate":"2017-01-01T11:06:01-08:00","relpermalink":"/post/g2p-whitepaper/","section":"post","summary":"In 2014, Dr. Margolin, Dr. Stuart and Dr. Ellrott wrote a draft white paper outlining the need for a computational model to efficiently communicate known Genotype/Phenotype association. This working group would eventually evolve into Variant Interpretation for Cancer Consortium VICC.\nMany of the ideas and goals changed of the project changed over the years. Below is the original whitepaper draft, to show how much the project has evolved.\nGA4GH Genotypes to Phenotypes (G2P) Task Team Motivation One of the most important goals driving the collection of genome sequence information is to understand how particular variants lead to observable phenotypes and treatment options.","tags":["GA4GH","G2P"],"title":"G2P Whitepaper","type":"post"},{"authors":null,"categories":null,"content":"Embed your slides or video here using shortcodes. Further details can easily be added using Markdown and $\\rm \\LaTeX$ math code.\n","date":1483257600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483257600,"objectID":"cd6d9d084287506b4668ad90c6aff50a","permalink":"https://ellrottlab.org/talk/example-talk/","publishdate":"2017-01-01T00:00:00-08:00","relpermalink":"/talk/example-talk/","section":"talk","summary":"Embed your slides or video here using shortcodes. Further details can easily be added using Markdown and $\\rm \\LaTeX$ math code.","tags":null,"title":"Example Talk","type":"talk"},{"authors":["Kyle Ellrott"],"categories":[],"content":"We've posted an article on the Google AI Blog about reproducibility in DREAM Challenges.\n","date":1473188501,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1473188501,"objectID":"ead9204550aee726d69290b5d279cbd4","permalink":"https://ellrottlab.org/post/reproducible-cloud/","publishdate":"2016-09-06T11:01:41-08:00","relpermalink":"/post/reproducible-cloud/","section":"post","summary":"We've posted an article on the Google AI Blog about reproducibility in DREAM Challenges.","tags":[],"title":"Reproducible Science: Cancer Researchers Embrace Containers in the Cloud","type":"post"},{"authors":null,"categories":null,"content":"The BioMedical Evidence Graph (BMEG) integrates different types of biomedical data into a unified graph for efficient application of machine learning and discovery algorithms across heterogeneous data types. BMEG will leverage the petabytes of genomics data available for tumor samples from repositories like the National Cancer Institute’s Genomic Data Commons to predict drug sensitivity, patient outcomes, and other clinically relevant phenotypes. The BMEG data model is instantiated in a scalable graph database optimized for storing and querying graphs containing terabytes of vertices and edges distributed across a multi-machine cluster. This graph is the store of record for the BMEG. It maintains the connections between projects, donors, samples, molecular data and treatment evidence and assures that these entities are associated correctly.\n","date":1461740400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461740400,"objectID":"b25ccbeda7438fec27f6520a7918abfe","permalink":"https://ellrottlab.org/project/bmeg/","publishdate":"2016-04-27T00:00:00-07:00","relpermalink":"/project/bmeg/","section":"project","summary":"BioMedical Evidence Graph","tags":["Data Systems"],"title":"BMEG","type":"project"},{"authors":null,"categories":null,"content":"https://www.synapse.org/DREAM_SMC\nThe ICGC-TCGA DREAM Genomic Mutation Calling Challenge (herein, The Challenge) is an international effort to improve standard methods for identifying cancer-associated mutations and rearrangements in whole-genome sequencing (WGS) data. Leaders of the International Cancer Genome Consortium (ICGC) and The Cancer Genome Atlas (TCGA) cancer genomics projects are joining with Sage Bionetworks and IBM-DREAM to initiate this innovative open crowd-sourced Challenge.\n","date":1461740400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461740400,"objectID":"329a54001ba75a869bdffd49a719371b","permalink":"https://ellrottlab.org/project/dream-smc/","publishdate":"2016-04-27T00:00:00-07:00","relpermalink":"/project/dream-smc/","section":"project","summary":"Somatic Mutation Calling","tags":["Dream Challenge"],"title":"DREAM-SMC","type":"project"},{"authors":null,"categories":null,"content":"https://www.synapse.org/SMC_RNA\nThe ICGC-TCGA DREAM Genomic Mutation Calling Challenge (herein, The Challenge) is an international effort to improve standard methods for identifying cancer-associated mutations and rearrangements in whole-genome sequencing (WGS) data. Leaders of the International Cancer Genome Consortium (ICGC) and The Cancer Genome Atlas (TCGA) cancer genomics projects are joining with Sage Bionetworks and IBM-DREAM to initiate this innovative open crowd-sourced Challenge.\n","date":1461740400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461740400,"objectID":"f46c96b8fba6948cf15178c1b62acefb","permalink":"https://ellrottlab.org/project/dream-rna/","publishdate":"2016-04-27T00:00:00-07:00","relpermalink":"/project/dream-rna/","section":"project","summary":"RNA Fusion Calling and Isoform Quantification","tags":["Dream Challenge"],"title":"DREAM-SMC-RNA","type":"project"},{"authors":null,"categories":null,"content":"https://ohsu-comp-bio.github.io/funnel/\nFunnel is a toolkit for distributed task execution with a simple API.\nA task describes metadata, state, input/output files, resource requests, commands, and logs. The task API has four actions: create, get, list, and cancel. Given a task, Funnel will queue it, schedule it to a worker, and track its state and logs. A worker will download input files, run a sequence of Docker containers, upload output files, and emits events and logs along the way.\nA wide variety of options make Funnel easily adaptable:\n BoltDB Elasticsearch MongoDB AWS Batch, S3, DynamoDB OpenStack Swift Google Cloud Storage, Datastore Kafka HPC support: HTCondor, Slurm, etc. and more  ","date":1461740400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461740400,"objectID":"6e17f64f1d44ca99b8e0943e123e6882","permalink":"https://ellrottlab.org/project/funnel/","publishdate":"2016-04-27T00:00:00-07:00","relpermalink":"/project/funnel/","section":"project","summary":"Funnel Task Execution Server","tags":["Data Systems"],"title":"Funnel","type":"project"},{"authors":null,"categories":null,"content":"The TCGA project combined DNA sequence data from three centers generated at Broad, Baylor, and Washington University. Mutation calling was performed independently at one or more of these centers for each of the tumor specific marker papers. The methods used for mutation calling varied as the project evolved over the years. The TCGA PanCancer Atlas MC3 set is a re-calling of uniform files to remove batch effects and enable pancancer analysis. We recognize the advantage to doing a uniform analysis where all the TCGA exome data was called on a standardized set of mutation callers. Further, we recognize the value of “containerizing” the procedures used, so that the methods are transparent and reproducible and sharable with the community. As detailed on this wikipage, the TCGA MC3dataset represents a uniform set of mutation calls. The BAM files used underwent a standardized local re-alignment to hg19 (Genome Reference Consortium GRCh37), six calling algorithms were applied, and a number of automated filters were applied. We strongly recommend that users review the information provided on caveats, data processing, filters, best practices, and acknowledgements before using this file.\n","date":1461740400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461740400,"objectID":"c872cd43c9cf6d1396bd18f71d428547","permalink":"https://ellrottlab.org/project/mc3/","publishdate":"2016-04-27T00:00:00-07:00","relpermalink":"/project/mc3/","section":"project","summary":"Multi-Center Mutation Calling in Multiple Cancers","tags":["Cancer Biology"],"title":"MC3","type":"project"},{"authors":["Adam D Ewing","Kathleen E Houlahan","Yin Hu","Kyle Ellrott","Cristian Caloian","Takafumi N Yamaguchi","J Christopher Bare","Christine P'ng","Daryl Waggott","Veronica Y Sabelnykova","ICGC-TCGA DREAM Somatic Mutation Calling Challenge participants","Michael R Kellen","Thea C Norman","David Haussler","Stephen H Friend","Gustavo Stolovitzky","Adam A Margolin","Joshua M Stuart","Paul C Boutros"],"categories":null,"content":"","date":1435734000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1435734000,"objectID":"2c3e137cd3d41d3199df6c372ad69094","permalink":"https://ellrottlab.org/publication/25984700/","publishdate":"2015-07-01T00:00:00-07:00","relpermalink":"/publication/25984700/","section":"publication","summary":"The detection of somatic mutations from cancer genome sequences is key to understanding the genetic basis of disease progression, patient survival and response to therapy. Benchmarking is needed for tool assessment and improvement but is complicated by a lack of gold standards, by extensive resource requirements and by difficulties in sharing personal genomic information. To resolve these issues, we launched the ICGC-TCGA DREAM Somatic Mutation Calling Challenge, a crowdsourced benchmark of somatic mutation detection algorithms. Here we report the BAMSurgeon tool for simulating cancer genomes and the results of 248 analyses of three in silico tumors created with it. Different algorithms exhibit characteristic error profiles, and, intriguingly, false positives show a trinucleotide profile very similar to one found in human tumors. Although the three simulated tumors differ in sequence contamination (deviation from normal cell sequence) and in subclonality, an ensemble of pipelines outperforms the best individual pipeline in all cases. BAMSurgeon is available at https://github.com/adamewing/bamsurgeon/. ","tags":null,"title":"Combining tumor genome simulation with crowdsourcing to benchmark somatic single-nucleotide-variant detection.","type":"publication"},{"authors":["Paul C Boutros","Adam D Ewing","Kyle Ellrott","Thea C Norman","Kristen K Dang","Yin Hu","Michael R Kellen","Christine Suver","J Christopher Bare","Lincoln D Stein","Paul T Spellman","Gustavo Stolovitzky","Stephen H Friend","Adam A Margolin","Joshua M Stuart"],"categories":null,"content":"","date":1396335600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1396335600,"objectID":"4bbb91f54fbdd32c19e010b24b49a2cc","permalink":"https://ellrottlab.org/publication/24675517/","publishdate":"2014-04-01T00:00:00-07:00","relpermalink":"/publication/24675517/","section":"publication","summary":"","tags":null,"title":"Global optimization of somatic variant identification in cancer genomes with a global community challenge.","type":"publication"},{"authors":["Larsson Omberg","Kyle Ellrott","Yuan Yuan","Cyriac Kandoth","Chris Wong","Michael R Kellen","Stephen H Friend","Josh Stuart","Han Liang","Adam A Margolin"],"categories":null,"content":"","date":1380610800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1380610800,"objectID":"ab13d0b3aeaecac8db0327968179b01a","permalink":"https://ellrottlab.org/publication/24071850/","publishdate":"2013-10-01T00:00:00-07:00","relpermalink":"/publication/24071850/","section":"publication","summary":"The Cancer Genome Atlas Pan-Cancer Analysis Working Group collaborated on the Synapse software platform to share and evolve data, results and methodologies while performing integrative analysis of molecular profiling data from 12 tumor types. The group's work serves as a pilot case study that provides (i) a template for future large collaborative studies; (ii) a system to support collaborative projects; and (iii) a public resource of highly curated data, results and automated systems for the evaluation of community-developed models.","tags":null,"title":"Enabling transparent and collaborative computational analysis of 12 tumor types within The Cancer Genome Atlas.","type":"publication"},{"authors":["Cancer Genome Atlas Research Network","John N Weinstein","Eric A Collisson","Gordon B Mills","Kenna R Mills Shaw","Brad A Ozenberger","Kyle Ellrott","Ilya Shmulevich","Chris Sander","Joshua M Stuart"],"categories":null,"content":"","date":1380610800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1380610800,"objectID":"2964816e99fd86b2368ee9ac182d6010","permalink":"https://ellrottlab.org/publication/24071849/","publishdate":"2013-10-01T00:00:00-07:00","relpermalink":"/publication/24071849/","section":"publication","summary":"The Cancer Genome Atlas (TCGA) Research Network has profiled and analyzed large numbers of human tumors to discover molecular aberrations at the DNA, RNA, protein and epigenetic levels. The resulting rich data provide a major opportunity to develop an integrated picture of commonalities, differences and emergent themes across tumor lineages. The Pan-Cancer initiative compares the first 12 tumor types profiled by TCGA. Analysis of the molecular aberrations and their functional roles across tumor types will teach us how to extend therapies effective in one cancer type to others with a similar genomic profile.","tags":null,"title":"The Cancer Genome Atlas Pan-Cancer analysis project.","type":"publication"},{"authors":["Mary Goldman","Brian Craft","Teresa Swatloski","Kyle Ellrott","Melissa Cline","Mark Diekhans","Singer Ma","Chris Wilks","Josh Stuart","David Haussler","Jingchun Zhu"],"categories":null,"content":"","date":1357027200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1357027200,"objectID":"8d86a981ecc3d81cce314d4bd8fea1ec","permalink":"https://ellrottlab.org/publication/23109555/","publishdate":"2013-01-01T00:00:00-08:00","relpermalink":"/publication/23109555/","section":"publication","summary":"The UCSC Cancer Genomics Browser (https://genome-cancer.ucsc.edu/) is a set of web-based tools to display, investigate and analyse cancer genomics data and its associated clinical information. The browser provides whole-genome to base-pair level views of several different types of genomics data, including some next-generation sequencing platforms. The ability to view multiple datasets together allows users to make comparisons across different data and cancer types. Biological pathways, collections of genes, genomic or clinical information can be used to sort, aggregate and zoom into a group of samples. We currently display an expanding set of data from various sources, including 201 datasets from 22 TCGA (The Cancer Genome Atlas) cancers as well as data from Cancer Cell Line Encyclopedia and Stand Up To Cancer. New features include a completely redesigned user interface with an interactive tutorial and updated documentation. We have also added data downloads, additional clinical heatmap features, and an updated Tumor Image Browser based on Google Maps. New security features allow authenticated users access to private datasets hosted by several different consortia through the public website.","tags":null,"title":"The UCSC Cancer Genomics Browser: update 2013.","type":"publication"},{"authors":["Kyle Ellrott","Christian M Zmasek","Dana Weekes","S Sri Krishna","Constantina Bakolitsa","Adam Godzik","John Wooley"],"categories":null,"content":"","date":1293868800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1293868800,"objectID":"fb6a220dd94dcbb87c94954a2e042766","permalink":"https://ellrottlab.org/publication/20961957/","publishdate":"2011-01-01T00:00:00-08:00","relpermalink":"/publication/20961957/","section":"publication","summary":"The Open Protein Structure Annotation Network (TOPSAN) is a web-based collaboration platform for exploring and annotating structures determined by structural genomics efforts. Characterization of those structures presents a challenge since the majority of the proteins themselves have not yet been characterized. Responding to this challenge, the TOPSAN platform facilitates collaborative annotation and investigation via a user-friendly web-based interface pre-populated with automatically generated information. Semantic web technologies expand and enrich TOPSAN's content through links to larger sets of related databases, and thus, enable data integration from disparate sources and data mining via conventional query languages. TOPSAN can be found at http://www.topsan.org.","tags":null,"title":"TOPSAN: a dynamic web database for structural genomics.","type":"publication"}]